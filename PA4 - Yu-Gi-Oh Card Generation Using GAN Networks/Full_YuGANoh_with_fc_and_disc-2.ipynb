{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import yuGANoh_with_fc_and_disc\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with zipfile.ZipFile('card.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((428,321)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataloader\n",
    "root_dir = 'data/card'\n",
    "batch_size = 45\n",
    "ygoDset = dataset.ygoCards(root_dir=root_dir,transform = transform)\n",
    "ygoLoader = DataLoader(ygoDset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview data\n",
    "batch = next(iter(ygoLoader))\n",
    "trans = transforms.ToPILImage()\n",
    "plt.imshow(trans(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network params\n",
    "latent_size = 100\n",
    "num_gan_features = 64\n",
    "num_disc_features = num_gan_features\n",
    "num_hidden_features = 256\n",
    "lr = 1e-4\n",
    "beta1 = 0.5\n",
    "num_epochs = 100\n",
    "similarity_features = 50\n",
    "lower_bound = 0.8\n",
    "bound = 1- lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialize network\n",
    "device = torch.device('cuda:0')\n",
    "gen = yuGANoh_with_fc_and_disc.Generator(latent_size,num_gan_features).to(device)\n",
    "disc = yuGANoh_with_fc_and_disc.Discriminator(num_disc_features,num_hidden_features,similarity_features,batch_size).to(device)\n",
    "gen.apply(yuGANoh_with_fc_and_disc.init_weights)\n",
    "print(gen)\n",
    "disc.apply(yuGANoh_with_fc_and_disc.init_weights)\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "noise = torch.randn(1,latent_size,1,1).to(device)\n",
    "optimizerD = optim.Adam(disc.parameters(),lr=2*lr,betas=(beta1,0.999), weight_decay = .0001)\n",
    "optimizerG = optim.Adam(gen.parameters(),lr=lr,betas=(beta1,0.999), weight_decay = .0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_loss(real_features,fake_features):\n",
    "    temp = torch.mean(real_features,axis=0) - torch.mean(fake_features,axis=0)\n",
    "    return torch.sum(temp*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen.load_state_dict(torch.load('gen22.pt'))\n",
    "#disc.load_state_dict(torch.load('disc22.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "gen_losses = []\n",
    "disc_losses = []\n",
    "\n",
    "print(\"Begin training\")\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0 and epoch%25 == 0:\n",
    "        lr*=2\n",
    "        optimizerD = optim.Adam(disc.parameters(),lr=lr,betas=(beta1,0.999), weight_decay = .0001)\n",
    "    for i,img in enumerate(ygoLoader,0):\n",
    "        #zero discriminator gradient\n",
    "        disc.zero_grad()\n",
    "        \n",
    "        \n",
    "        #run real image through discriminator\n",
    "        img = img.to(device)\n",
    "        #img = normalize_tensors(img) + 0.1*torch.randn_like(img).to(device)\n",
    "        if epoch < 10:\n",
    "            img = img + 0.1*torch.randn_like(img).to(device)\n",
    "        b_size = img.shape[0]\n",
    "        features_real, output = disc(img)\n",
    "        output = output.squeeze()\n",
    "        #real_label = 1\n",
    "        #label = torch.ones_like(output).to(device)\n",
    "        label = 1 - bound*torch.rand_like(output)\n",
    "        disc_loss_real = criterion(output,label)\n",
    "        disc_loss_real.backward(retain_graph = True)\n",
    "        \n",
    "        \n",
    "        #now run a fake batch through generator.\n",
    "        inp = torch.randn(b_size,latent_size,1,1).to(device)\n",
    "        gen_out = gen(inp)\n",
    "        features_fake, fake_out = disc(gen_out)\n",
    "        fake_out = fake_out.squeeze()\n",
    "        #fake_label = 0\n",
    "        label_fake = label*0\n",
    "        disc_loss_fake = criterion(fake_out,label_fake)\n",
    "        disc_loss_fake.backward(retain_graph = True)\n",
    "        total_loss = disc_loss_real + disc_loss_fake       \n",
    "        optimizerD.step()\n",
    "        \n",
    "        #train the generator\n",
    "        #we already have a generator pass with gen_out=gen(inp)\n",
    "        gen.zero_grad()\n",
    "        model_loss = feature_loss(features_real,features_fake)\n",
    "        model_loss.backward(retain_graph = True)   \n",
    "        optimizerG.step()\n",
    "        '''\n",
    "        #train the generator again\n",
    "        #we already have a generator pass with gen_out=gen(inp)\n",
    "        gen.zero_grad()\n",
    "        features_out_real , model_out = disc(gen_out)\n",
    "        model_out = model_out.squeeze()\n",
    "        model_loss = feature_loss(features_out_real,features_fake)\n",
    "        model_loss.backward()   \n",
    "        optimizerG.step()'''\n",
    "        \n",
    "        #check_individual_norm(gen)\n",
    "        #check_individual_norm(disc)\n",
    "        \n",
    "        if i%50 == 0:\n",
    "            disc_losses.append(total_loss.item())\n",
    "            gen_losses.append(model_loss.item())\n",
    "            print('Epoch: '+str(epoch) + ' iter: ' + str(i) + ' lossG: ' + str(gen_losses[-1]) + ' lossD: ' + str(disc_losses[-1]))\n",
    "            out_img = gen(noise)\n",
    "            #out_img = undo_normalize(out_img)\n",
    "            trans = transforms.ToPILImage()\n",
    "            plt.imshow(trans(out_img[0].cpu()))\n",
    "            if gen_losses[-1] == 0.0:\n",
    "                break\n",
    "            if disc_losses[-1] == 0.0:\n",
    "                break\n",
    "            print('discriminator gradient L2 Norm')\n",
    "            #check_norm(disc)\n",
    "            print('generator gradient L2 Norm')\n",
    "            #check_norm(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    print(total_norm)\n",
    "    \n",
    "def normalize_tensors(inp):\n",
    "    return (inp-0.5)*2\n",
    "\n",
    "def undo_normalize(inp):\n",
    "    return inp/2 + 0.5\n",
    "\n",
    "def check_individual_norm(model):\n",
    "    for p in model.parameters():\n",
    "        if p.grad is None:\n",
    "            print(str(p.name)+' is None')\n",
    "            continue\n",
    "        print(str(p.name) +': '+  str(p.grad.data.norm(2).item()**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(9):\n",
    "    noise = torch.randn(1,latent_size,1,1).to(device)\n",
    "    out_img = gen(noise)\n",
    "    #out_img = undo_normalize(out_img)\n",
    "    trans = transforms.ToPILImage()\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(trans(out_img[0].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(disc_losses)\n",
    "plt.plot(gen_losses)\n",
    "plt.legend(['disc_losses','gen_losses'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), 'gen22_new.pt')\n",
    "torch.save(disc.state_dict(), 'disc22_new.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(disc_losses,'disc22_loss_weight_new-dec_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen_losses,'gen22_loss_weight_new-dec_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = torch.randn(3*2,3,4)\n",
    "A = torch.randn(4,3*2)\n",
    "A.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.Tensor([[[1,1],[2,2]],[[3,3],[4,4]],[[2,1],[2,4]],[[11,3],[4,3]]])\n",
    "A = A.transpose(0,2)\n",
    "print(A.shape)\n",
    "A = A.repeat(A.shape[2],1,1,1)\n",
    "print(A.shape)\n",
    "B = A.transpose(0,-1)\n",
    "print(B.shape)\n",
    "C = torch.exp(-torch.sum(torch.abs(B-A),dim=2))\n",
    "print(C.shape)\n",
    "D = torch.sum(C,dim = 2)\n",
    "print(D.shape)\n",
    "print(D[0])\n",
    "print(D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(3,2)\n",
    "print(A.shape)\n",
    "print(A)\n",
    "torch.sum(A,dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
