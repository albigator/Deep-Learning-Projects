{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import pickle as pkl\n",
    "import csv\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torchvision import utils\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loader import *\n",
    "import vocabulary_struct\n",
    "import AnnoNet\n",
    "#import AnnoNetRNN as AnnoNet # uncomment this line for vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vocab_File', 'rb') as f:\n",
    "    vocab = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('TrainImageIds.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    trainIds = list(reader)\n",
    "\n",
    "trainIds = [int(i) for i in trainIds[0]]\n",
    "with open('TestImageIds.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    testIds = list(reader)\n",
    "\n",
    "testIds = [int(i) for i in testIds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valIds = trainIds[:int(0.2*len(trainIds))]\n",
    "del trainIds[:int(0.2*len(trainIds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.94s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "#Implement normalization later\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(250),\n",
    "    transforms.CenterCrop(250),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                             (0.229, 0.224, 0.225))\n",
    "])\n",
    "train_loader = get_loader(root = './data/images/train/',\n",
    "                          json = './data/annotations/captions_train2014.json',\n",
    "                          ids = trainIds,\n",
    "                          vocab = vocab,\n",
    "                          transform = transform,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4)\n",
    "val_loader = get_loader(root = './data/images/train/',\n",
    "                          json = './data/annotations/captions_train2014.json',\n",
    "                          ids = valIds,\n",
    "                          vocab = vocab,\n",
    "                          transform = transform,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4)\n",
    "test_loader = get_loader(root = './data/images/test/',\n",
    "                          json = './data/annotations/captions_val2014.json',\n",
    "                          ids = testIds,\n",
    "                          vocab = vocab,\n",
    "                          transform = transform,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        #torch.nn.init.xavier_uniform_(m.bias.data)\n",
    "        torch.nn.init.zeros_(m.bias.data)\n",
    "        \n",
    "epochs     = 100\n",
    "#criterion = # Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "AnnoNet = AnnoNet.AnnoNet(vocab_size = len(vocab), batch_size = batch_size, embedding_dim=256,hidden_dim = 512, hidden_units=1)\n",
    "AnnoNet.apply(init_weights)\n",
    "optimizer = optim.Adam(AnnoNet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "if use_gpu:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    #fcn_model = fcn_model.cuda()\n",
    "    #fcn_model = fcn_model.to(device)\n",
    "    AnnoNet = AnnoNet.to(device)\n",
    "    \n",
    "def train(batch_size, check_num = 5):\n",
    "    counter = 0 \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        rolling_loss = 0\n",
    "        theCounter = 0\n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if use_gpu:\n",
    "                inputs = X.to(device)# Move your inputs onto the gpu\n",
    "                labels = tar.to(device,dtype=torch.int64)# Move your labels onto the gpu\n",
    "            else:\n",
    "                inputs, labels = (X,tar)# Unpack variables into inputs and labels\n",
    "            \n",
    "            #print(\"lengths: \", Y)\n",
    "            outputs = AnnoNet(inputs, labels, Y)\n",
    "            del inputs\n",
    "            torch.cuda.empty_cache()\n",
    "            #output_captions, output_labels = output_captioning(outputs)\n",
    "            '''if iter % 100 == 0:\n",
    "                print(output_captions)'''\n",
    "            #print(outputs.shape)\n",
    "            labels = pack_padded_sequence(labels, Y, batch_first=True)\n",
    "            #print(labels.data.shape)\n",
    "            loss = criterion(outputs, labels.data)\n",
    "            #Acc, _, _, _ = prediction_and_Accuracy(outputs, labels)\n",
    "            del outputs,labels\n",
    "            torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "            \n",
    "            rolling_loss += loss.item()\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "            theCounter += 1\n",
    "            \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        Normalizing_Factor = theCounter * batch_size\n",
    "        losses.append(rolling_loss / Normalizing_Factor)\n",
    "        loss_val = val(epoch, batch_size)\n",
    "        val_losses.append(loss_val)\n",
    "        AnnoNet.train()\n",
    "        \n",
    "        #Early Stopping for validation Loss\n",
    "        if epoch == 0:\n",
    "            torch.save(AnnoNet.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            if torch.argmin(torch.Tensor(val_losses)) == epoch:\n",
    "                torch.save(AnnoNet.state_dict(), 'best_model.pt')\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "        torch.save(val_losses,\"val_losses\")\n",
    "        \n",
    "        torch.save(losses,\"train_loss\")\n",
    "        \n",
    "        if counter == check_num:\n",
    "            print(\"early stop achieved\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "def val(epoch, batch_size):\n",
    "    AnnoNet.eval()\n",
    "    ts = time.time()\n",
    "    rolling_loss = 0\n",
    "    rolling_acc = 0\n",
    "    counter = 0\n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs = X.to(device)# Move your inputs onto the gpu\n",
    "            labels = tar.to(device,dtype=torch.int64)# Move your labels onto the gpu\n",
    "        else:\n",
    "            inputs, labels = (X,tar)# Unpack variables into inputs and labels\n",
    "\n",
    "        #print(\"lengths: \", Y)\n",
    "        outputs = AnnoNet(inputs, labels, Y)\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "        labels = pack_padded_sequence(labels, Y, batch_first=True)\n",
    "        loss = criterion(outputs, labels.data)\n",
    "        rolling_loss += loss.item()\n",
    "        del outputs,labels\n",
    "        torch.cuda.empty_cache()\n",
    "        #rolling_acc += Acc\n",
    "        \n",
    "        if iter% 10 == 0:\n",
    "            print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "        del loss\n",
    "        torch.cuda.empty_cache()\n",
    "        counter += 1\n",
    "    \n",
    "    print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "    Normalizing_Factor = counter * batch_size\n",
    "    rolling_loss /= Normalizing_Factor\n",
    "    print(\"Average loss: \",rolling_loss)\n",
    "    \n",
    "    return rolling_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: 10.132027626037598\n",
      "epoch0, iter10, loss: 6.512854099273682\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-47e0f5f520b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4fc6d32a1b50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch_size, check_num)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnnoNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m#output_captions, output_labels = output_captioning(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             '''if iter % 100 == 0:\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    459\u001b[0m     \"\"\"\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(batch_size)\n",
    "print(\"yay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
